>参考文档：
>
>[Ray v2 Architecture](https://docs.google.com/document/d/1tBw9A4j62ruI5omIJbMxly-la5w4q_TjyJgJL_jN2fI/preview?tab=t.0#heading=h.16g8domf57dq)
>
>[Ray -分布式计算框架架构设计详解 v2](https://www.qin.news/ray-v2/)

# 综述

Ray 是一个为了给分布式提供通用的 API 发明出来的分布式计算框架，希望通过简单但通用的抽象编程方式，让系统自动完成所有的工作。Ray 的设计者基于这个理念让 Ray 可以跟 Python 紧密相连，能够通过很少的代码就能处理业务，而其它的并行、分布式内存管理等问题都不用担心，Ray 会根据这些资源的情况自动调度和缩放。

![img](./images/36_Ray2.0 - 01.png)



# 2.0 带来的新特性

- 原本的 Global Control Store 改名叫 Global Control Service，简称 GCS，有着全新的设计更加简单和可靠。
- 分布式调度器（包括调度策略和置放群组）能让你更方便地扩展功能。
- 在可靠性和容错性方面进行改进，包括从故障节点中恢复 object reconstruction 和 GCS 的容错机制。
- 增加了像 KubeRay 等方便集群管理的一些工具。



# 架构设计概述

## 主要概念解释

### Task

一个用于远程调用的函数，在不同的调用方的进程上执行，也可以是在不同的机器上执行。Task 可以是无状态的也可以是有状态的（如 Actor）。

### Object

应用所需的值，这些是任务返回的或者通过 `ray.put`创建的值，这些对象是一旦创建就不可以修改的。可以通过 `ObjectRef` 引用。以下也可能被称为对象。

### Actor

有状态的工作进程，Actor 的任务必须使用特定的方式提交给指定的实例，可以在执行过程中修改 Actor 的内部状态。你可以理解为是一个常驻进程，或者是有状态的 Task。

### Driver

程序的 root 或者是主程序，一般指放 `ray.init` 的代码的应用。

### Job

来自同个 Driver 的 Task 和 Actor 的集合，Driver 和 Job 是 1:1 映射关系。是一个逻辑上的概念，其含义为运行一次用户侧代码所所涉及到的所有生成的 Task 以及产生的状态的集合。



### 设计

![img](./images/36_Ray2.0 - 02.png)

协议概览(大部分通过 gRPC):
a. 任务执行，对象引用计数。
b. 本地资源管理。
c. 远程/分布式资源管理。
d. 分布式对象传输。
e. 大型对象的存储和检索。检索是通过 `ray.get` 或在任务执行过程中进行。或者用对象的值替换一个任务的ObjectID参数时。
f. 调度器从远程节点获取对象，以满足本地排队任务的依赖满足。

### 组件

![img](./images/36_Ray2.0 - 03.png)

Ray 集群是由一个或者多个 worker 节点组成，每个 worker 节点由以下物理进程组成：

- 一个或多个的 worker 进程，负责任务的提交和执行，worker 进程要么是无状态的，要么是一个 actor。初始工作线程由机器的 CPU 数量决定。每个工作节点会存储：
  - 一个 ownership 表，worker 引用的对象的系统元数据，例如引用技术和对象位置。
  - 进程内存储，存放一些小对象。
- raylet，用于管理每个节点上的共享资源，与工作进程不同的是，raylet 是在所有 worker  中共享的：
  - Scheduler，负责资源管理、任务放置和完成将 Task 的参数存储在分布式的 Object Store 中。
  - Object Store，一个共享内存存储，也被称为 Plasma Object Store。负责存储、转移和溢出（spilling，如果 Object Store 满了会移动到外部存储）大型对象。集群中各个 Object Store 共同构建了 Ray 的分布式对象存储。

每一个工作进程和 raylet 都被分配了一个唯一的 28-byte 的标识符和一个 ip 地址、端口。

同样的地址和端口在工作进程死亡后重新恢复时可以重复使用，

但是唯一 ID 不会。工作进程和 raylet 是 fate-share 的，一个出故障另外一个就无法使用了。

其中有个节点会被指定为 Head 节点，除了有上述进程外还会托管 GCS 和 Driver。在新版本的 GCS 是一个管理集群的元数据的服务器，比如 actor 的位置、worker 存储的 key-value 对等。GCS 还管理少量的集群几笔的操作包括调度预占用组和 actor 以及确定集群中哪些是成员。一般来说 GCS 中保存的数据很少被调用，但是可以被集群中几乎所有的 worker 节点使用。**GCS 容错机制是在 v2 版本中加入的，它可以运行在任何节点或者多个节点，之前只能在指定的节点。**

Dirver 是一个用于指定的用于运行最上级的代码的应用的节点，它能提交任务但是并不能在自己上面执行。虽然 Driver 可以在任何节点上运行，但默认情况下只在 Head 节点运行。

Head 节点还包含了其它类似集群级别服务的自动缩放、任务提交等等。

### Ownership（所有权关系）

![img](./images/36_Ray2.0 - 04.png)

大多数的系统是通过一种叫做 Ownership 的分散控制的方式管理的，这个方式是指每一个 `ObjectRef` 都是由所在的 worker 进程管理的，该 worker 或者也被叫做 owner 需要确保 Task 的执行、创建 value。

一般有两种方式去创建 `ObjectRef`，在下面两个例子中，owner 都是实际运行的 worker 的进程。

- x_ref = f.remote()
- x_ref = ray.put()

换句话来说 owner 是生成和初始化  `ObjectRef` 的 worker，如果 `ObjectRef` 由 Task 返回，那么这个值是由远程 worker 创建的而不是拿到返回值的 worker。

在 2.0 版本中，这个方式带来了更好的性能和更简单的结构、提升了可靠性，每个 application 是相对独立的，一个远程调用故障了并不会影响另一个。

但 ownership 还是存在一些问题，像如果要解析 `ObjectRef` ，就必须能够访问对象的 owner，这意味着 object 和 owner 是 fate-share（一个挂掉，另一个一起挂掉）。其次是目前无法转移所有权。

### 内存模型

![img](./images/36_Ray2.0 - 05.png)

Ray 通过以下方式使用内存：

1. Ray 的 worker 在执行任务或者运行 Actor 时会使用堆内存，由于 Ray 的 Task 和 Actor 一般是并行运行，开发人员应该关注每个 Task 的堆内存的情况。如果内存压力过大，Ray 会自动释放掉消耗内存大的进程。
2. 当一个 worker 调用 `ray.put()` 或者从一个 Task 返回时，它会将提供的值复制到 Ray 的共享内存对象存储中。然后 Ray 会让这些对象在整个集群中可访问，在发生故障时尝试恢复它们，如果对象存储超过其配置的容量，则将它们转移其它存储设备，并在所有 `ObjectRef`超出范围时将它们垃圾回收。对于可以被 zero-copy 的反序列化的值，会在取出时将指向共享缓冲区的指针给 worker，其它则是被反序列化到接收的 worker 的堆内存中。
3. 如果 Object 足够小（默认 100 kb），Ray 将直接把值存储在 owner 的内存中，而不是在 Raylet 里的共享对象存储。任何其它使用这个对象的 worker 都会把值直接复制到自己的内存里。同样 Ray 也会对他们进行垃圾回收。
4. Ray 的元数据也会使用堆内存，大部分元数据都很小，可能就几 kb。例如：

- GCS 的所有 Actor、所有节点、所有的预占用组集群。
- Raylet 的本地排队的 Task、这些任务的对象参数、对象。
- Worker 的提交了等待处理的任务或者可能需要重新通过  lineage reconstruction 执行的。拥有的对象等等。

### 语言运行时

![img](./images/36_Ray2.0 - 06.png)

所有 Ray 核心组件都在 C++ 中实现。Ray 通过一个称为“core worker”的 C++ 库支持Python、Java 和 C++ 前端。该库实现了所有权表、进程内存储，并管理与其他工作程序和 raylet 的 gRPC 通信。

### Task 的生命周期

![img](./images/36_Ray2.0 - 07.png)

所有者需要能够指定被提交来的任务并且将 `ObjectRef` 解析成一个普通的值。Driver 去 Raylet 中请求需要的值，将值和 Task A 都交给 Worker 1 运行，Driver 拥有 Task A 结果的所有权，而 Worker 1 有 Task B 的所有权。

所有者可以将普通的 Python 对象作为任务参数传递，如果参数传递的值很小，会直接将这个值从所有者的内存中复制到 Task 中，让执行者可以直接引用。如果传递的参数很大，所有者会先通过 ray.put 放入共享对象存储，然后将  `ObjectRef` 作为参数传递。

Ray 会在每一次自动进行上面的流程，如果你喜欢两个 Task 共用一个请显式调用 put。

所有者也可以直接将其它的  `ObjectRef` 作为任务参数传递，如果 `ObjectRef` 对应的值很小，会直接放到 Task 的 specification 中，否则传递  `ObjectRef` 。任务执行时会将  `ObjectRef` 解析成具体的值。

一旦所有任务依赖项就绪，所有者就从分布式调度器请求资源来执行任务。分布式调度器尝试获取资源，并通过分布式内存将 Task 的 specification 中的任何  `ObjectRef` 参数获取到本地节点。一旦资源和参数都可用，调度程序就会批准请求。

所有者通过 gRPC 将 Task 的 specification 发送给 worker 来调度。执行 Task 后 worker 必须存储返回的值。如果返回的值很小会直接返回给所有者，如果很大会存到共享内存存储将  `ObjectRef` 返回，允许所有者引用返回值而不需要先拿到本地节点。

当 Ray 的 Task 第一次被调用时，它会被存储到 GCS 中，稍后会由被租用的 worker 获取出函数的定义进行运行。

Task 可能在运行过程中可能会出现应用级错误（worker 进程仍然是活跃的状态）或者是系统级错误（worker 进程已经死亡或者故障）中断抛出。

默认情况下，由于应用程序级别错误而失败的任务不会自动重试。异常被捕获并存储为任务的返回值。在 2.0 中，用户可以传递应用程序级异常的白名单，Ray 可以自动重试。由于系统级错误而失败的任务会自动重试，你可以指定最多重试次数。

### Object 的生命周期

![img](./images/36_Ray2.0 - 08.png)

对象是一个不可变的值，可以从 Ray 集群中的任何位置存储和引用。对象的所有者是通过提交创建任务或调用 ray.put 创建初始化 `ObjectRef` 的 worker。所有者负责管理对象的生存期。Ray 保证如果所有者活着，对象最终可能会被解析为其值（或者在工作程序失败的情况下抛出错误）。如果所有者已死亡，尝试获取对象的值将引发异常，即使仍然存在对象的物理副本。

每个工作程序存储其拥有的对象的引用计数。仅在以下操作期间计算引用：

- 向任务传递 `ObjectRef` 或包含 `ObjectRef` 作为参数的对象。
- 从任务中返回 `ObjectRef` 或包含 `ObjectRef` 的对象。

对象可以存储在所有者的进程内存存储或分布式对象存储中。进程内内存存储是在所有者的堆上分配的，不强制限制存储量。因为 Ray 只存储很小的对象。过多的小对象存储在内存中可能会引起内存不足的问题而导致进程被结束。存储在分布式对象存储的对象首先会存储在共享内存存储中，共享内存存储默认是机器内存的 30%，在达到上限后转移到本地磁盘上。

你可以通过 `ray.get` 将 `ObjectRef` 转为实际的值或者是将 `ObjectRef` 作为参数传递，具体的执行者会自动解析。

如果出现系统级的故障，对象存储在分布式内存存储中，并且该对象的所有副本都因 raylet 故障而丢失，则该对象就丢失了。Ray 会尝试通过重建的方式去恢复这个对象，如果所有者进程也死亡了，则无法重建。











