>参考文档：
>
>[Ray v2 Architecture](https://docs.google.com/document/d/1tBw9A4j62ruI5omIJbMxly-la5w4q_TjyJgJL_jN2fI/preview?tab=t.0#heading=h.16g8domf57dq)
>
>[Ray -分布式计算框架架构设计详解 v2](https://www.qin.news/ray-v2/)

# 概述

## API理念

Ray 旨在为分布式计算提供一个通用的 API。实现这一目标的核心在于提供简单但通用的编程抽象，让系统处理所有复杂的工作。正是这种理念使开发者能够将 Ray 与现有的 Python 库和系统结合使用。

Ray 使用者只需通过少量的 Python 原语表达逻辑，而系统会处理物理执行相关的事务，例如并行性和分布式内存管理。Ray 用户以资源为核心来思考集群管理，而系统则根据这些资源请求自动处理调度和自动扩展。

![img](./images/36_Ray2.0 - 01.png)

*Ray 提供了一个通用的 API，包括任务（tasks）、执行器（actors）和对象（objects），用于构建分布式应用程序*

一些应用可能需要不同的系统级权衡，这些权衡无法通过核心抽象集合来表达。因此，Ray API 的第二个目标是允许应用对系统行为进行细粒度控制。这个目标是通过一组可配置的参数来实现的，这些参数可以用来修改系统行为，例如任务调度、故障处理和应用生命周期管理。

## 系统范围

Ray 旨在促进分布式应用和库的开发与组合。具体而言，这包括粗粒度的弹性工作负载（即无服务器计算类型）、机器学习训练（例如 Ray AIR）、在线服务（例如 Ray Serve）、数据处理（例如 Ray Datasets、Modin、Dask-on-Ray）以及临时计算（例如，Python 应用的并行化，将不同的分布式框架结合在一起）。

Ray 的 API 使开发者能够轻松地在一个分布式应用中组合多个库。例如，Ray 的任务和执行器可以调用或被来自 Ray 内部的分布式训练（例如 torch.distributed）或在线服务工作负载所调用。Ray AI Runtime（AIR）就是通过在底层组合其他 Ray 库构建的。从这个意义上说，Ray 是一个出色的“分布式粘合”系统，因为它的 API 足够通用且高效，能够作为不同工作负载类型之间的接口。

## 系统设计目标

Ray 架构的核心原则是 API 简单性和通用性，而核心系统目标是性能（低开销和水平可扩展性）和可靠性。有时，我们愿意为了实现这些核心目标而牺牲其他一些理想目标，比如架构的简洁性。例如，Ray 包含分布式引用计数和分布式内存等组件，这些组件增加了架构复杂性，但它们是性能和可靠性所必需的。

在性能方面，Ray 建立在 gRPC 之上，并且在许多情况下可以匹配或超越直接使用 gRPC 的性能。与单独使用 gRPC 相比，Ray 使得应用程序更容易利用并行和分布式执行、分布式内存共享（通过共享内存对象存储）以及动态创建轻量级服务（即执行器）。

在可靠性方面，Ray 的内部协议旨在确保在故障期间的正确性，同时对常见情况添加的开销极低。Ray 实现了分布式引用计数协议，以确保内存安全，并提供了各种选项来从故障中恢复。

由于 Ray 用户将计算表达为资源而非机器，Ray 应用程序可以在无需任何代码修改的情况下，从笔记本电脑透明地扩展到集群。Ray 的分布式调度器和对象管理器被设计为支持这种无缝扩展，且开销极低。

## 相关系统

以下表格将 Ray 与几个相关系统类别进行了对比。请注意，我们省略了高级库的对比（例如 RLlib、Tune、RaySGD、Serve、Modin、Dask-on-Ray、MARS-on-Ray）；这些对比超出了本文档的范围，本文档主要关注 Ray 核心部分。您也可以参考 Ray 上的社区库完整列表。

| 模块                                         | 介绍                                                         |
| -------------------------------------------- | ------------------------------------------------------------ |
| **Cluster Orchestrators(集群协调器)**        | Ray 可以运行在 Kubernetes 或 SLURM 等集群协调器之上，提供更轻量级、语言集成的原语，即任务和执行器，而不是容器和服务。 |
| **Parallelization Frameworks(并行化框架)**   | 与 Python 并行化框架（如 multiprocessing 或 Celery）相比，Ray 提供了更通用、更高性能的 API。Ray 系统还显式支持内存共享。 |
| **Data Processing Frameworks(数据处理框架)** | 与数据处理框架（如 Spark、Flink、MARS 或 Dask）相比，Ray 提供了更低级和更狭窄的 API。这使得该 API 更加灵活，适合作为“分布式粘合”框架。另一方面，Ray 本身并不理解数据模式、关系表或流数据；这些功能仅通过库提供（例如，Modin、Dask-on-Ray、MARS-on-Ray）。 |
| **Actor Frameworks(执行器框架)**             | 与专门的执行器框架（如 Erlang 和 Akka）不同，Ray 与现有编程语言集成，支持跨语言操作并使用语言本地库。Ray 系统还透明地管理无状态计算的并行性，并显式支持执行器之间的内存共享。 |
| **HPC Systems(高性能计算系统（HPC）)**       | 许多 HPC 系统暴露了消息传递接口，这是比任务和执行器更低级的接口。这可能为应用提供更大的灵活性，但可能需要付出更多的开发努力。许多这些系统和库（例如 NCCL、MPI）还提供了优化的集体通信原语（例如 allreduce）。Ray 应用可以通过初始化 Ray 执行器组之间的通信组来利用这些原语（例如 RaySGD 与 torch 分布式结合的方式）。 |

## 2.0 带来的新特性

自 1.x 版本白皮书以来：

- **全局控制存储**（Global Control Store）现已更名为 **全局控制服务**（Global Control Service, GCS），并且进行了完全的设计更新，以简化协调和提高可靠性。
- **分布式调度器** 提供了扩展的功能和灵活性，包括调度策略和资源分配组（placement groups）。
- 在可靠性和容错性方面进行了全面改进，包括对象重建以从节点故障中恢复，以及 GCS 的容错能力。
- 扩展了管理和与 Ray 集群交互的工具集，新增了作业提交、KubeRay（Ray 在 Kubernetes 上运行）和应用可观测性等功能。



# 架构概述

## 应用概念

**任务**（Task） - 远程函数调用。这是一个在与调用者不同的进程上执行的函数调用，可能还会在不同的机器上执行。任务可以是无状态的（一个 `@ray.remote` 函数）或有状态的（`@ray.remote` 类的方法 —— 见下文的执行器）。任务是异步执行的：`.remote()` 调用会立即返回一个或多个 `ObjectRef`（即未来对象），可以用来获取返回值。

**对象**（Object） - 应用中的值。这些值由任务返回或通过 `ray.put` 创建。对象是不可变的：一旦创建就不能修改。工作进程可以通过 `ObjectRef` 引用一个对象。

**执行器**（Actor） - 有状态的工作进程（`@ray.remote` 类的实例）。执行器任务必须通过句柄提交，句柄是对特定执行器实例的 Python 引用，并且可以在执行过程中修改执行器的内部状态。

**驱动程序**（Driver） - 程序根本，或者说是“主”程序。运行 `ray.init()` 的代码就是驱动程序。

**作业**（Job） - 从同一驱动程序递归起源的任务、对象和执行器的集合，以及它们的运行时环境。驱动程序和作业之间有一一对应的关系。



## 设计

![img](./images/36_Ray2.0 - 02.png)

协议概览(大部分通过 gRPC):
a. 任务执行，对象引用计数。
b. 本地资源管理。
c. 远程/分布式资源管理。
d. 分布式对象传输。
e. 大型对象的存储和检索。检索是通过 `ray.get` 或在任务执行过程中进行。或者用对象的值替换一个任务的ObjectID参数时。
f. 调度器从远程节点获取对象，以满足本地排队任务的依赖满足。

### 组件

![img](./images/36_Ray2.0 - 03.png)

*一个Ray集群*

一个 Ray 集群由一个或多个工作节点组成，每个节点包括以下物理进程：

* **工作进程**：负责任务提交和执行。工作进程可以是无状态的（可以重复使用来执行任何 `@ray.remote` 函数）或是执行器（只能执行其 `@ray.remote` 类的方法）。每个工作进程都与特定的作业相关联。初始工作进程的默认数量等于机器上的 CPU 数量。每个工作进程存储：

  - **所有权表**：用于存储工作进程所引用对象的系统元数据，例如，存储引用计数和对象位置。

  - **进程内存存储**：用于存储小型对象。

* **Raylet**：Raylet 管理每个节点上的共享资源。与工作进程不同，Raylet 是所有并发运行的作业共享的。Raylet 包含两个主要组件，分别在不同的线程上运行：

  - **调度器**：负责资源管理、任务调度和执行任务的参数，这些参数存储在分布式对象存储中。集群中的各个调度器组成了 Ray 的分布式调度器。

  - **共享内存对象存储（也称为 Plasma 对象存储）**：负责存储、传输和溢出大对象。集群中的每个对象存储组成了 Ray 的分布式对象存储。

其中一个工作节点被指定为 **头节点**。除了上述进程，头节点还托管：

- **全局控制服务**（GCS）：GCS 是一个服务器，负责管理集群级的元数据，例如执行器的位置，以键值对的形式存储，这些键值对可能会被工作进程本地缓存。GCS 还管理一些集群级操作，包括执行器和资源分配组的调度、确定集群节点的成员资格。一般来说，GCS 管理的是较少访问但可能被集群中大多数或所有工作进程使用的元数据。这样设计是为了确保 GCS 的性能不会对应用程序性能产生关键影响。GCS 的容错性是 Ray 2.0 中的新增功能，允许 GCS 运行在任意多个节点上，而不仅仅是指定的头节点。
- **驱动程序进程**（Driver）：驱动程序是一个特殊的工作进程，用于执行顶层应用程序（例如 Python 中的 `__main__`）。驱动程序可以提交任务，但无法执行任何任务。需要注意的是，驱动程序进程可以运行在任何节点上，但默认情况下通常运行在头节点上。
- 其他集群级服务：这些服务处理作业提交、自动扩展等操作。

### 所有权关系（Ownership）

![img](./images/36_Ray2.0 - 04.png)

大部分系统元数据是通过一个名为“所有权”的去中心化概念来管理的。这个概念意味着应用中的每个 `ObjectRef` 将由一个单独的工作进程管理。这个工作进程或“所有者”负责确保执行创建该值的任务，并促使 `ObjectRef` 解析到其底层值。

创建 `ObjectRef` 有两种方式。在这两种情况下，所有者是调用此代码的 `x_ref` 的工作进程。

```python
x_ref = f.remote()
x_ref = ray.put()
```

换句话说，所有者是生成初始 `ObjectRef` 的工作进程。需要注意的是，这个工作进程可能与创建 `ObjectRef` 值的工作进程不同。例如，如果 `ObjectRef` 是由任务返回的，那么值将由远程工作进程创建。

**所有权的好处（与 Ray 版本 <0.8 中使用的更集中式设计相比）：**

- **低任务延迟**（约 1 个往返时延，<200 微秒）。频繁访问的系统元数据局部化在需要更新它的进程中。
- **高吞吐量**（每个客户端约 10,000 个任务/秒；在集群中线性扩展至百万任务/秒），因为系统元数据通过嵌套的远程函数调用自然分布在多个工作进程中。
- **简化架构**。所有者集中处理所需的逻辑，以安全地进行对象和系统元数据的垃圾回收。
- **提高可靠性**。工作进程的故障可以根据应用结构相互隔离，例如，某个远程调用的失败不会影响另一个调用。

**所有权带来的一些权衡：**

- 为了解析一个 `ObjectRef`，对象的所有者必须是可达的。这意味着对象将与其所有者共享命运。有关对象恢复和持久化的更多信息，请参见 **对象故障** 和 **对象溢出**。
- 目前，所有权无法转移。

### 内存模型

![img](./images/36_Ray2.0 - 05.png)

*典型的 Ray 节点使用的内存类型。GCS（未显示）包含集群级的元数据，例如节点和执行器的信息。*

Ray 可能以以下方式使用内存：

1. **Ray 工作进程在执行任务或执行器时使用的堆内存。**Ray 工作进程在执行任务或执行器时会执行用户定义的代码。由于 Ray 任务和执行器通常是并行运行的（最多与核心数量相同），应用程序开发人员应当关注每个任务的堆内存使用。如果堆内存压力过高，Ray 会首先尝试终止占用内存较多的工作进程，以保护对象存储和其他系统级进程中的系统状态。

2. **由大型 Ray 对象（由 `ray.put()` 创建或由 Ray 任务返回的值）使用的共享内存。**当工作进程调用 `ray.put()` 或从任务中返回时，它会将提供的值复制到 Ray 的共享内存对象存储中。Ray 随后会在集群中使这些对象可用，在发生故障时尝试恢复它们，如果对象存储超出其配置的容量，则将它们溢出，并在所有 `ObjectRefs` 超出作用域后进行垃圾回收。对于可以进行零拷贝反序列化的值，通过 `ray.get` 或作为任务参数传递的 `ObjectRef` 会直接返回指向共享内存缓冲区的指针给工作进程。所有其他值将会反序列化到接收工作进程的堆内存中。

3. **由小型 Ray 对象（由 Ray 任务返回的对象）使用的堆内存。**如果对象足够小（默认值为 100KB），Ray 会直接将值存储在所有者的“内存”对象存储中，而不是 Raylet 共享内存对象存储中。任何读取该对象的工作进程（例如，通过 `ray.get`）将直接将该值复制到自己的堆内存中。Ray 还通过与大对象相同的协议自动对这些对象进行垃圾回收。

4. **由 Ray 元数据使用的堆内存。**这是 Ray 分配的内存，用于管理应用程序的元数据。大部分元数据以任务规范或对象的元数据（例如引用计数）形式存在。从 Ray v2.0 开始，预计每个仍在作用域内的 `ObjectRef` 的总元数据开销为几 KB。以下是系统级进程及其预期内存占用的简要总结：

   - **GCS**：总执行器数量、总节点数量、总资源分配组数量。
   - **Raylet**：本地排队的任务数量、这些任务的对象参数数量、存储在本地共享内存或本地磁盘中的对象数量。
   - **工作进程**：已提交但仍待处理或可能通过血统重建重新执行的任务数量、所有的对象数量、在语言前端中处于作用域内的对象数量。

   >在 Ray 中，**任务规范（Task Specification，简称 Task Spec）** 是指描述一个任务的元数据和运行信息的结构化数据。它定义了任务的所有必要细节，以便 Ray 系统可以调度和执行该任务。任务规范在任务被提交时生成，并被用来协调任务的执行。
   >
   >任务规范通常包含以下内容：
   >
   >**任务的标识信息**
   >
   >- 唯一任务 ID（Task ID）：用于标识任务。
   >- 调用任务的驱动程序或工作器的信息（Owner）。
   >
   >**函数和代码信息**
   >
   >- 任务要调用的函数或方法的定义和引用。
   >- 函数的序列化版本（Pickled Function），这样其他工作器可以获取并执行它。
   >
   >**任务的输入参数**
   >
   >- 参数值：如果参数是小对象（例如标量、字符串等），它们会直接嵌入任务规范中。
   >- 对象引用（ObjectRefs）：如果参数是大对象或 Ray 对象，它们以 `ObjectRef` 的形式传递，需要从分布式对象存储中获取。
   >
   >**资源需求**
   >
   >- 任务所需的计算资源：如 CPU 核心数、GPU 数量、内存等。
   >- 特定资源标签：如果任务需要特定的节点或硬件。
   >
   >**返回值信息**
   >
   >- 返回值的 ObjectRefs：用来存储任务的输出数据。
   >
   >**依赖关系**
   >
   >- 任务执行前需要满足的依赖：如输入的 ObjectRefs 是否已完成或可用。
   >
   >**调度信息**
   >
   >- 调度策略：如任务的优先级或任务在集群中的放置策略（Placement Groups）。

### 语言运行时

所有 Ray 核心组件均使用 C++ 实现。Ray 通过一个名为“核心工作者”（core worker）的通用嵌入式 C++ 库支持 Python、Java 和（实验性）C++ 前端。该库实现了所有权表、进程内存储，并负责与其他工作进程和 raylet 的 gRPC 通信。由于该库是用 C++ 实现的，因此所有语言运行时共享 Ray 工作者协议的通用高性能实现。



![img](./images/36_Ray2.0 - 06.png)

*Ray 工作进程通过 CoreWorker 库与其他 Ray 进程交互*

## Task 的生命周期

所有者负责确保已提交任务的执行，并促进返回的 `ObjectRef` 与其底层值的解析。

![img](./images/36_Ray2.0 - 07.png)

*提交任务的进程被视为结果的所有者，并负责从 raylet 获取资源以执行该任务。在此示例中，驱动程序是 `A` 结果的所有者，而 `Worker 1` 是 `B` 结果的所有者。*

所有者可以将普通 Python 对象作为任务参数传递。如果任务参数的值较小，它会直接从所有者的进程内对象存储中复制到任务规范中，以供执行的工作器引用。

如果任务的参数较大，则所有者会在底层调用 `ray.put()` 存储该对象，然后将生成的 ObjectRef 作为任务参数传递。需要注意的是，Ray 对象不会自动进行内存化或去重；如果同一个大型 Python 对象被传递给两个不同的任务，这将导致两次单独的 `ray.put()` 调用，并创建两个独立的对象。因此，如果需要将同一个对象传递给多个任务，建议显式调用 `ray.put()`。

所有者也可以将其他 ObjectRef 作为任务参数传递。当任务提交时，所有者会等待所有 ObjectRef 参数变为可用。需要注意的是，这些依赖项不需要是本地的；**一旦依赖项在集群中的任何位置可用，所有者就认为它们已经准备就绪。**如果 ObjectRef 的实际值较小，所有者会将该值直接复制到任务规范中，与小型 Python 值处理方式类似。否则，所有者会将 ObjectRef 的元数据附加到任务规范中，任务执行器必须在执行任务之前将 ObjectRef 解析为实际值。这是为了避免将大型参数传输到任务调用者。

一旦所有任务依赖项都已就绪，所有者会向分布式调度器请求资源以执行任务。分布式调度器尝试获取资源，并通过分布式内存将任务规范中的任何 ObjectRef 参数提取到本地节点。一旦资源和参数都可用，调度器批准请求并返回一个已分配给所有者的工作器地址。

>在 Ray 中，**本地节点** 是指当前任务将被调度和执行的物理或虚拟机器（节点）。具体来说，当任务被提交时，分布式调度器会尝试选择一个最合适的节点来执行任务，这个节点就被称为任务的本地节点。

>Q：假设任务是由节点A分发给节点B执行的，那么调度器是位于节点A，调度器如何知道节点B上的资源准备情况？
>
>调度器通过 **GCS** 和各节点的 **Raylet** 获取全局和本地资源状态。即使任务是由节点 A 提交给节点 B，调度器也能实时了解节点 B 的资源准备情况，并确保任务的顺利分配和执行。这种设计结合了中心化（GCS 提供全局视图）和去中心化（Raylet 管理本地资源）的架构，使 Ray 能够高效调度任务并动态适应资源变化。

所有者通过 gRPC 将任务规范发送给已分配的工作器以调度任务。在执行任务后，工作器必须存储返回值。如果返回值较小，工作器会将这些值直接内联返回给所有者，所有者会将其复制到自己的进程内对象存储中。如果返回值较大，工作器会将对象存储在其本地共享内存存储中，并回复所有者，指示这些对象现在位于分布式内存中。类似于将 ObjectRef 作为任务参数传递，这允许所有者引用返回值，而无需将它们提取到本地节点。

当首次调用 Ray 任务时，其定义会被序列化并存储在 GCS 中。随后，被分配的工作器会获取序列化的函数定义，并对其进行反序列化以运行任务。

任务可能会因错误而终止。Ray 将任务错误分为两种类型：

1. 应用层错误：这是指在 worker 进程仍然存活的情况下，任务因错误而终止。例如，一个在 Python 中抛出 `IndexError` 的任务。
2. 系统层错误：这是指 worker 进程意外死亡的情况。例如，一个进程发生段错误（segfault）或 worker 的本地 raylet 崩溃。

由于应用层错误导致的任务默认不会自动重试。错误会被捕获并作为任务的返回值存储。在 Ray 2.0 中，用户可以传递一个应用层异常的白名单，允许 Ray 自动重试这些特定的异常。由于系统层错误导致的任务则可能会自动重试，直到达到指定的重试次数。

## Object 的生命周期

![img](./images/36_Ray2.0 - 08.png)

对象是一个不可变的值，可以在 Ray 集群中的任何地方存储和引用。对象的所有者是创建初始 `ObjectRef` 的 worker，通常是通过提交创建任务或调用 `ray.put`。所有者负责管理对象的生命周期。Ray 保证，如果所有者存活，最终可以解析对象的值（如果 worker 失败，则抛出错误）。如果所有者已死亡，即使对象仍有物理副本，尝试获取对象的值时也会抛出异常。

每个 worker 为其拥有的对象存储引用计数。有关如何跟踪引用的更多信息，请参见引用计数。引用仅在以下操作中计数：

- 将 `ObjectRef` 或包含 `ObjectRef` 的对象作为参数传递给任务。
- 从任务中返回 `ObjectRef` 或包含 `ObjectRef` 的对象。

对象可以存储在所有者的进程内存存储中，也可以存储在分布式对象存储中。进程内存存储分配在所有者的堆上，并且不强制执行容量限制。这是因为 Ray 只在此存储中存储小对象；如果作用域内的小对象过多，可能会导致所有者进程因内存不足而被杀死。存储在分布式对象存储中的对象首先存储在共享内存中。**共享内存对象存储强制执行用户可配置的容量限制（默认为机器 RAM 的 30%），并在达到容量时将对象溢出到本地磁盘。**这个决策旨在减少每个对象的内存占用和解析时间。

当没有发生故障时，只要对象仍然在作用域内（引用计数非零），所有者保证最终会有至少一个副本的对象变得可用。有关更多详细信息，请参见内存管理。

有两种方法可以将 `ObjectRef` 解析为其值：

- 对 `ObjectRef(s)` 调用 `ray.get`。
- 将 `ObjectRef` 作为参数传递给任务。执行任务的 worker 会解析 `ObjectRef` 并用解析后的值替换任务参数。

当对象很小的时候，它可以通过直接从所有者的进程内存存储中检索来解析。大对象存储在分布式对象存储中，必须使用分布式协议进行解析。有关更多详细信息，请参见对象解析。

当没有发生系统级故障时，解析保证最终会成功，但可能会抛出应用级异常。如果发生故障，解析可能会抛出系统级异常（例如，ray.exceptions.WorkerCrashedError），但永远不会挂起。如果对象存储在分布式内存中，并且所有副本因 raylet 故障而丢失，Ray 会尝试通过重建自动恢复丢失的对象。如果所有者进程死亡，对象也会失败。

## Actor 的生命周期

Actor 的生命周期和元数据（例如，IP 地址和端口）由 GCS 管理。每个 Actor 的客户端可以将这些元数据缓存到本地，并利用它通过 gRPC 直接向 Actor 发送任务。

![img](./images/36_Ray2.0 - 09.png)

*与 Task 提交不同，Task 完全去中心化并由 Task 的所有者管理，Actor 的生命周期是由 GCS 服务集中管理的*

当在 Python 中创建一个 actor 时，创建的 worker 会构建一个特殊的任务，即 actor 创建任务，该任务运行 actor 的 Python 构造函数。创建的 worker 等待 actor 创建任务的任何依赖项变为就绪，这与非 actor 任务类似。**一旦完成，创建的 worker 会异步地将 actor 注册到 GCS**。然后，GCS 会通过调度 actor 创建任务来创建  actor。这类似于非演员 actor 的调度，只不过它指定的资源会在 actor 进程的生命周期内被获取。

同时，创建 actor 的 Python 调用会立即返回一个“actor handle”，即使创建任务尚未被调度，该句柄也可以被使用。随后，将 actor 句柄作为参数的任务，直到演员创建任务完成后才会被调度。有关更多细节，请参见 actor 创建。

对于 actor 的任务执行与普通任务类似：它们返回 **futures**，通过 gRPC 直接提交给 actor 进程，并且在所有 `ObjectRef` 依赖项解决之前不会执行。主要有两个不同点：

1. 默认情况下，执行 actor 任务不需要从调度器获取资源。这是因为在 actor 创建任务被调度时，已经为其生命周期分配了资源。

2. 对于每个调用 actor 的任务，任务将按提交的顺序执行。这是因为这些任务被假设为会修改 actor 状态。

当 actor 的创建者退出，或者集群中没有更多待处理任务或句柄时，actor 将自动清理（有关如何确定这一点，请参见引用计数）。请注意，这对于 **detached actor** 不适用，**detached actor** 是设计为长生命周期的 actor，可以通过名称引用，并且必须通过 `ray.kill(no_restart=True)` 显式清理。有关 actor 失败的更多信息，请参见 **Actor Death**。

在某些情况下，可能希望打破 actor 任务按提交顺序依次执行的要求。为支持这种用例，Ray 还提供了 actor 并发的选项，通过 **async actor**（可以使用 asyncio 事件循环并发执行任务）或 **threaded actor**（使用线程并行执行多个任务）。从调用者的角度来看，向这些 actor 提交任务与向常规 actor 提交任务是相同的。唯一的区别是，当任务在 actor 上运行时，它会被投递到后台线程或线程池中，而不是直接在主线程上运行。Ray API，如任务提交和 `ray.get`，是线程安全的，但用户需要对 actor 代码中的其他线程安全性负责。

## 故障模型

### 系统模型

Ray worker 节点被设计为同质的，因此任何单一节点的丢失都不会导致整个集群的崩溃。目前唯一的例外是头节点，因为它托管了 GCS。在 2.0 版本中，我们为 GCS 故障容错添加了实验性支持，这使得 GCS 在重启时能够最小化对集群其他部分的干扰。

所有节点都会被分配一个唯一标识符，并通过心跳与彼此通信。GCS 负责决定集群的成员资格，即当前存活的节点。GCS 会为任何超时的节点 ID 创建墓碑，这意味着必须在该节点上启动一个新的 **raylet**，并分配不同的节点 ID 才能重新利用物理资源。一个仍然存活的 **raylet** 会在听到自己超时时退出。当前节点故障检测不处理网络分区：如果一个 worker节点与 GCS 发生网络分区，它将超时并被标记为死亡。

每个 **raylet** 会将任何本地 worker进程的死亡报告给 GCS。GCS 会广播这些故障事件，并利用它们来处理 actor的死亡。所有 worker进程与其所在节点的 **raylet** 共享命运。

**raylet** 负责在单个 worker进程故障后，防止集群资源和系统状态泄漏。对于一个已经失败的 worker进程（无论是本地还是远程），每个 **raylet** 负责：

1. 释放任务执行所需的集群资源，如 CPU。这是通过终止所有分配给失败 worker的 worker来完成的（见资源履行）。任何该失败 worker提出的未完成资源请求也会被取消。
2. 释放该 worker拥有的分布式对象存储内存（见内存管理）。这也会清理与该对象相关的对象目录条目。

### 应用模型

![img](./images/36_Ray2.0 - 10.png)

系统故障模型意味着 Ray 图中的任务和对象将与其所有者共享命运。例如，如果运行 `a` 的 **worker** 在这种情况下失败，那么它的子树中创建的任何对象和任务（灰色部分的 `b` 和 `z`）将会被收集。如果 `b` 是在 `a` 的子树中创建的 **actor**，则同样适用（见 **Actor Death**）。这有以下几个含义：

1. 任何其他存活的进程如果尝试获取此类对象的值，将会收到应用级异常。例如，如果 `z` 的 **ObjectRef** 在上述场景中已经传递给了驱动程序，驱动程序在调用 `ray.get(z)` 时将收到错误。
2. 通过修改程序将不同的任务放置在不同的子树中（即通过嵌套函数调用），可以隔离故障。
3. 应用程序将与驱动程序共享命运，驱动程序是所有权树的根节点。

避免共享命运行为的主要应用选项是使用 **detached actor**，该 **actor** 的生命周期可以超越其原始驱动程序，并且只能通过程序中的显式调用销毁。**detached actor** 本身可以拥有其他任务和对象，这些任务和对象在销毁后将与该 **actor** 共享命运。

Ray 提供了一些选项来帮助透明恢复，包括自动任务重试和 **actor** 重启。从 v1.3 版本开始，**object spilling** 也可以用来使对象在其所有者的生命周期之后依然存在。从 v2.0 开始，Ray 默认启用非 **actor** 任务的对象重建。

## Object 管理

![img](./images/36_Ray2.0 - 11.png)

*进程内存储 vs 分布式对象存储。这展示了当提交一个依赖于对象（`x`）的任务（`a`）时，内存分配的不同方式*

一般来说，小对象会存储在其所有者的进程内存储中，而大对象则存储在分布式对象存储中。做出这个决策是为了减少每个对象的内存占用和解析时间。请注意，在后一种情况下，一个占位符对象会存储在进程内存储中，以指示该对象实际上存储在分布式对象存储中。

进程内存储中的对象可以通过直接内存拷贝快速解析，但当被多个进程引用时，可能会因额外的拷贝而导致更高的内存占用。单个 **worker** 的进程内存储容量也受限于该机器的内存容量，限制了在任何给定时刻可以引用的此类对象的总数量。对于被多次引用的对象，吞吐量可能还会受到所有者进程的处理能力的限制。

相比之下，解析分布式对象存储中的对象至少需要一次从 **worker** 到该 **worker** 本地共享内存存储的 RPC。如果该 **worker** 的本地共享内存存储还没有该对象的拷贝，可能还需要额外的 RPC。另一方面，由于共享内存存储是通过共享内存实现的，同一节点上的多个 **worker** 可以引用同一对象的拷贝。如果一个对象能够以零拷贝的方式反序列化，这可以减少总体内存占用。使用分布式内存还允许进程引用没有本地存储的对象，这意味着进程可以引用总大小超过单台机器内存容量的对象。最后，吞吐量可以随着分布式对象存储中节点数量的增加而扩展，因为多个拷贝可能存储在不同的节点上。

### Object 解析（Object resolution）

解析是将 **ObjectRef** 转换为底层物理值的过程，即在调用 `ray.get` 或将其作为任务参数传递时。**ObjectRef** 包含两个字段：

1. 一个唯一的 28 字节标识符。这是生产该对象的任务的 ID 与该任务至今创建的对象数量的整数值的拼接。
2. 对象所有者（**worker** 进程）的地址。这包括 **worker** 进程的唯一 ID、IP 地址和端口，以及本地 **raylet** 的唯一 ID。

小对象通过直接从所有者的进程内存储中复制来解析。例如，如果所有者调用 `ray.get`，系统会从本地进程内存储中查找并反序列化该值。如果所有者提交一个依赖任务，则通过直接将该值复制到任务规范中内联对象。同样地，如果一个借用者尝试解析该值，对象值将直接从所有者复制，跳过下节中描述的大对象解析协议。

![img](./images/36_Ray2.0 - 12.png)

*对象 `x` 最初在节点 2 上创建，例如因为返回该值的任务在该节点上运行。以下展示了所有者（任务调用者）调用 `ray.get` 时的步骤：*

1. *在所有者处查找对象的位置。*
2. *选择一个位置并发送请求，获取该对象的拷贝。*
3. *接收对象。*

大对象存储在分布式对象存储中，必须通过分布式协议进行解析。如果该对象已经存储在引用持有者的本地共享内存存储中，引用持有者可以通过 IPC 检索该对象。这将返回指向共享内存的指针，该指针可能同时被同一节点上的其他 **worker** 引用。

如果对象在本地共享内存存储中不可用，引用持有者会通知其本地 **raylet**，然后 **raylet** 尝试从远程 **raylet** 获取该对象的拷贝。**raylet** 会从对象目录中查找位置，并请求从其中一个 **raylet** 转移该对象。自 Ray v1.3+ 版本起，对象目录存储在所有者处（之前存储在 GCS 中）。

>分布式协议和 **gRPC** 协议并不完全相同，但它们存在一些关联。Ray 的分布式协议是专门为任务调度、对象管理和资源分配设计的，而 gRPC 是 Ray 用来实现每个Woker Process之间通信的底层工具之一。

### 内存管理（Memory management）

对于远程任务，对象值由正在执行的工作程序计算。如果值很小，worker 将直接向所有者回复值，并将其复制到所有者的进程内存储中。一旦所有引用超出范围，此值将被删除。

![img](./images/36_Ray2.0 - 13.png)

*主副本与可收回副本。主副本（节点2）不符合逐出资格。但是，节点1（通过“ray.get”创建）和节点3（通过任务提交创建）上的副本可以在内存不够时被逐出。*

如果该值较大，则执行工作程序将该值存储在其本地共享内存存储中。共享内存对象的初始副本称为主副本。主副本是唯一的。

因为只要范围中有引用，它就不会被释放。raylet 通过保存对存储对象的物理共享内存缓冲区的引用来“锁定”主副本，从而防止对象存储区将其逐出。相反，如果在本地内存不够时，对象的其它副本可能会被 LRU 逐出，除非开发人员在使用这个对象。

在大多数情况下，主副本是要创建的对象的第一个副本。如果初始副本因故障而丢失，所有者将尝试根据对象的可用位置指定新的主副本。

一旦对象引用计数变为 0，对象的所有副本最终都会被自动垃圾收集。所有者会立即从进程中存储中删除小对象。raylets 将从分布式对象存储中异步删除大型对象。

>引用计数元数据始终存储在 **对象所有者的进程内存** 中，由对象所有者完全管理。

raylets 还管理分布式对象传输，该传输基于对象当前需要的位置创建对象的其他副本，例如，如果依赖于对象的任务被调度到远程节点。

![img](./images/36_Ray2.0 - 14.png)

*节点上可存储的对象类型。对象要么由工作程序创建（例如节点 1 上的 A、B 和 C），要么从其他节点传输副本，因为本地工作程序需要该副本（例如节点 2 上的 A、B 和 C）。*

由于以下任何原因，对象可能存储在节点的共享内存对象存储中：

- 它是由本地工作进程通过 “ray.get” 或 “ray.wait” 请求的。一旦工作进程完成“ray.get” 请求，就可以释放这些资源。注意，对于可以是 zero-copy，从 “ray.get” 返回的 Python 的值直接引用共享内存缓冲区，因此对象将被“固定”，直到该Python值超出范围。
- 它由在该节点上执行的前一个任务返回。一旦没有对对象的更多引用，或者一旦对象被引用，这些对象就可以被释放。
- 它是由该节点上的本地工作进程通过 “ray.put” 创建的，一旦不再引用对象（上图中节点1上的对象A、B 和 C），就可以释放这些对象。
- 它是在该节点上排队或执行的任务的参数。一旦任务完成或不再排队，就可以释放这些资源。节点 2 上的对象 B 和 C 都是这样的例子，因为它们的下游任务 g 和 h 尚未完成。
- 此节点以前需要它，例如，已完成的任务需要它。节点 2 上的对象 A 就是一个例子，因为 f 已经完成了执行。如果内存不足，这些对象可能会基于本地 LRU 被逐出。当ObjectRef 超出范围时，它们也会被快速释放（例如，在 f 完成并调用 “del A” 之后，A 从节点 2 中删除）。

### 内存不足的情况

对于小对象，Ray 当前**不会对每个工作进程的进程存储施加内存限制**。你需要确保小对象不会太多，导致所有者进程因内存不足而被终止。

Ray 对共享内存对象施加限制由 raylet 负责强制执行此限制。下面是可以存储在节点上的不同类型的共享内存对象的可视化，具有基本的优先级。

![img](./images/36_Ray2.0 - 15.png)

对象创建请求由 raylet 排队，并在（6）中有足够的内存用于创建对象时提供服务。如果需要更多内存，raylet将选择要从（3）-（5）中逐出的对象以腾出空间。即使在所有这些对象被逐出后，raylet 也可能没有空间用于新对象。如果应用程序所需的总内存大于集群的内存容量，就会发生这种情况。

如果驱逐后需要更多的空间，raylet 首先会在整个集群中的每个 worker 处触发特定于语言的垃圾收集。在语言前端看到的 ObjectRef 似乎很小，因此不太可能触发通常的特定语言垃圾回收机制。然而，ObjectRef 的实际内存占用可能非常大，因为物理值存储在 Ray 的对象存储中的其它位置，并且可能存储在与语言级别 ObjectRef 不同的节点上。因此，当任何 Ray 对象存储达到容量时，我们会在所有工作线程上触发语言级别的垃圾收集，这将清除所有不需要的 ObjectRef，并允许从对象存储中释放物理值。

raylet 会在触发溢出之前，让 worker 有时间异步垃圾收集 ObjectRef。溢出允许从对象存储中释放（2）中的主副本，即使对象仍然可以被引用。如果禁用溢出，则应用程序将在可配置超时后接收 ObjectStoreFullError。溢出可能代价很高，并且增加任务执行的长时间；因此，一旦对象存储达到可配置阈值（默认为80%），Ray 也会急切地溢出对象，以确保可用空间。

注意，即使启用了对象溢出，对象存储仍可能耗尽内存。如果同时使用的对象太多（1），则会发生这种情况。为了减轻这种情况，raylet 限制了正在执行的任务的参数的总大小，因为在任务完成之前无法释放参数。默认上限为对象存储内存的 70%。这确保了只要没有其他对象因 “ray.get” 请求而被活动锁定，任务就可以创建一个对象存储容量的 30%。

目前，raylet 没有为 worker 的“ray.get”请求的对象实现类似的上限，因为这样做可能会导致任务之间的死锁。因此，如果对大型对象有过多的并发 “ray.get” 请求，raylet 仍可能耗尽共享内存。发生这种情况时，raylet 会将对象分配为本地磁盘上的内存映射文件（默认情况下为/tmp）。由于I/O开销，这样分配的对象性能较差，但即使对象存储已满，它也允许应用程序继续运行。如果本地磁盘已满，则分配将失败，之后应用程序将收到 OutOfDiskError。

![img](./images/36_Ray2.0 - 16.png)

### 对象溢出（Object spilling）

Ray 默认支持在对象存储的容量用完后将对象溢出到外部存储。

外部存储通过可插拔接口实现。默认情况下支持两种类型的外部存储：

本地存储。默认情况下选择本地磁盘，这样 Ray 用户就可以使用对象溢出功能，而无需任何额外配置。

分布式存储（实验性，目前提供 Amazon S3）。访问速度可能较慢，但这可以提供更好的容错性，因为数据可以在工作节点故障后存活。

对象溢出由几个部分构成：

**raylet 内**

- 本地对象管理器：跟踪对象元数据，例如外部存储中的位置，并协调 IO woker 和与其它 raylet 的通信。
- 共享内存对象存储。

**IO workers**

用于溢出和恢复对象的 python 进程。

**外部存储**

用于存放无法放入共享内存对象存储的对象。

![img](./images/36_Ray2.0 - 17.png)

*raylet 管理一个 I/O worker 池。I/O  worker 从本地共享内存对象存储和外部存储进行读/写。*

当 Ray 没有足够的内存容量来创建对象时，它会引发对象溢出。请注意，Ray 只溢出对象的主副本：这是通过执行任务或通过 “Ray.put” 创建的对象的初始副本。非主副本可以立即被逐出，这种设计确保了集群中每个对象最多有一个溢出的副本。只有在对象溢出后，或者应用程序中没有更多引用时，主副本才可收回。

协议如下所示，重复执行，直到留出足够的空间来创建任何需要的对象：

- Raylet（本地对象管理器）查找本地对象存储中的所有主副本。
- Raylet将这些对象的溢出请求发送给 IO worker。
- IO worker 将对象值及其元数据写入外部存储。
- 一旦主副本溢出到外部存储，raylet 将使用溢出对象的位置更新对象目录。
- 对象存储区收回主副本。
- 一旦对象的引用计数变为0，所有者就会通知 raylet 可以删除该对象。raylet 向 IO worker 发送请求，以从外部存储中删除对象。

溢出的对象将根据需要恢复。当请求对象时，Raylet 要么通过向本地 IO worker 发送恢复请求从外部存储恢复对象，要么从不同节点上的 Raylet 获取副本。远程 Raylet 可能会将对象溢出到本地存储（例如，本地SSD）上。在这种情况下，远程 raylet 直接从本地存储读取对象并将其发送到网络。

由于 IO 开销，每个文件一个对象溢出许多小对象是低效的。对于本地存储，操作系统将很快耗尽 inode。如果对象小于 100MB，Ray 会将对象融合到单个文件中以避免此问题。

Ray 还支持多目录溢出，这意味着它使用安装在不同位置的多个文件系统。当多个本地磁盘连接到同一台机器时，这有助于提高溢出带宽和最大外部存储容量。

目前存在的限制：

- 使用本地文件存储时，如果存储溢出对象的节点丢失，则溢出对象将丢失。在这种情况下，Ray 将尝试恢复对象，就像它从共享内存中丢失一样。
- 如果所有者丢失，则无法访问溢出的对象，因为所有者存储对象的位置。
- 应用程序当前正在使用的对象被 “pinned”。例如，如果 Python 的 Driver 有一个指向ray.get 获得的对象的原始指针（例如，共享内存上的 numpy 数组），则该对象将被固定。在应用程序释放这些对象之前，它们是不可使用溢出机制的。正在运行的任务的参数也固定在任务的持续运行的时间内，运行结束后才可以。

>存储溢出对象的节点指的是IO Worker。

### 引用计数

**每个 worker 存储其所拥有的每个对象的引用计数。**所有者的本地引用计数包括本地Python 引用计数和作为所有者提交的任务所依赖的对象。当 Python 的 “ObjectRef” 被释放时，前者将递减。当依赖于对象的任务成功完成时（注意，以应用程序级异常结束的任务视为成功），后者将递减。

`ObjectRef` 也可以通过将它们复制到另一个进程。接收 “ObjectRef” 副本的过程称为借用者。例如：

```python
@ray.remote
def temp_borrow(obj_refs):

  # Can use obj_refs temporarily as if I am the owner.

  x = ray.get(obj_refs[0])

@ray.remote
class Borrower:

  def borrow(self, obj_refs):

    # We save the ObjectRef in local state, so we are still borrowing the object once this task finishes.

   self.x = obj_refs[0]

x_ref = foo.remote()

temp_borrow.remote([x_ref])  # Passing x_ref in a list will allow `borrow` to run before the value is ready.

b = Borrower.remote()

b.borrow.remote([x_ref])  # x_ref can also be borrowed permanently by an actor.
```

通过跟踪这些引用。简言之，每当引用“逃离”本地作用域时，所有者就会添加到本地引用计数中。例如，在上面的代码中，当调用 “temp_borrow.remote” 和“b.borrow.remoto” 时，所有者会增加 x_ref 的挂起任务计数。一旦任务完成，它会向所有者回复一个仍在借用的引用列表。例如，在上述代码中，“temp_borrow” 的 worker 会回答说，它不再借用 “x_ref”，而 “Borrower” 的 worker 会回答说它仍在借用 “x_ref”。

如果 worker 仍在借用任何对象，所有者会将 worker 的 ID 添加到本地的 borrowers 列表中。borrowers 保持第二个本地参考计数，与所有者类似，一旦 borrowers 的本地参考计数变为 0，所有者要求 borrowers 回复。此时，所有者可以将 worker 从 borrowers 列表中删除并收集对象。在上述示例中，“borrowers” 的 worker 正在永久借用引用，因此所有者在 “borrowers” 自身超出范围或死亡之前不会释放对象。

borrowers 也可以递归地添加到所有者列表中。如果 borrowers 本身将 “ObjectRef” 传递给另一个进程，就会发生这种情况。在这种情况下，当 borrowers 响应所有者其本地引用计数为 0 时，它还包括其创建的任何新 borrowers 。所有者反过来使用相同的协议联系这些新的 borrowers。

根据上述一共包含下面不同的引用计数：

**本地 python 引用计数**

等于 worker 进程中 python 的引用技术，在取消或者分配 python 中的 ObjectRef 递增或递减。

**提交任务计数**

依赖于尚未完成执行的对象的任务数。当 worker 提交任务时递增。当任务完成时递减。如果对象足够小，可以存储在进程内存储中，则在将对象复制到 Task specification 中时，此计数会提前递减。

**借用者（Borrowers）**

当前借用 “ObjectRef” 的进程的一组工作 ID。借用者是一个 worker 但不是所有者并且拥有 Python 本地实例的 ObjectRef，每个借用者还会维护一个本地的借用者列表，允许借用者将 “ObjectRef” 发送给另一借用者，而无需联系所有者 。当任务被传递一个 ObjectRef 并在任务结束后继续使用它时，该任务通知其调用方它正在借用该对象。然后，被调用的 worker 将任务 的 worker 的 ID 添加到此集合中。

当 ObjectRef 的引用计数为 0 时，如果是所有者本身会自动删除，所有者向每个借用者发送异步 RPC。借用者在收到后将其删除，如果无法联系到借用者，会从列表中删除。

如果借用者被移除，worker 会等待来自所有者的 rpc，一旦 worker 本地的引用计数为 0，worker 就会将借用者弹出并告知所有者。

**嵌套计数（Nested count）**

在作用域中且其值包含有 `ObjectRef` 的 `ObjectRef` 数。

**谱系计数（Lineage count）**

启用对象重建时使用。依赖于此 “ObjectRef” 且其值存储在分布式对象存储中（可能在失败时丢失）的任务数。在提交依赖于对象的任务时递增。如果任务返回的“ObjectRef”超出范围，或者任务完成并在进程内存储中返回值，则递减。

>在分布式计算中，**谱系（Lineage）** 是指任务和对象之间的依赖关系图。这种图结构记录了哪些任务生成了哪些对象，以及这些任务的输入对象来源于哪些其他任务。
>
>**谱系计数（Lineage Count）** 是指一个对象或任务在依赖关系图中被引用的次数。

**特殊情况（Corner cases）**

```python
x_ref = foo.remote()
@ray.remote
def capture():
  ray.get(x_ref)  # x_ref is captured. It will be pinned as long as the driver lives.
```

创建引用的常规做法是将 ObjectRef 作为任务参数直接传递给其它 worker，或者在数据结构（如列表）内部传递。也可以通过使用 “ray.cloudpickle” 对 “ObjectRef” 进行额外引用。在上面代码下，ray 无法跟踪对象的序列化副本或确定 ObjectRef 何时已反序列化（例如，如果 ObjectRef 由非 Ray 进程反序列化）。因此，将向对象的计数添加一个永久引用，以防止对象超出范围。

带 out-of-band 序列化的其它方法包括使用 “pickle” 或自定义序列化方法。与上述类似，Ray 无法跟踪这些引用。访问反序列化的 ObjectRef（即通过调用“ray.get”或作为任务参数传递）可能会导致引用计数异常。

**执行器句柄（Actor handles）**

用于跟踪（非分离）Actor 的生命周期。虚拟对象用于代表 Actor。此对象的 ID 是根据 Actor 创建任务的 ID 计算的。Actor 的创建者拥有虚拟对象。

当 Python 的 Actor handle 被释放时，这会减少虚拟对象的本地引用计数。当在 Actor handle 上提交任务时，这会增加虚拟对象的已提交任务计数。当一个 Actor handle 被传递给另一个进程时，接收进程被算作虚拟对象的借用者。一旦引用计数达到 0，所有者就通知 GCS 服务可以安全地销毁 Actor。

Actor 是**不会被 Ray 自动回收的**，需要显式删除。

**与 Python GC**

当对象是 Python 中引用循环的一部分时，Python 不能保证这些对象会被及时地垃圾回收。所有ObjectRef 可以在分布式对象存储中恶意地保持 Ray 对象的活动状态，当对象存储接近容量时，**Ray 会周期性地在所有 Python worker 中触发“gc.collect（）”**。这确保 Python 引用循环不会导致虚假的对象存储已满状态。

>Python 的垃圾回收系统由 **引用计数** 和 **循环垃圾回收（Cycle Garbage Collection）** 两部分组成，循环垃圾回收器专门用于检测和清理循环引用的问题。

### 对象失败（Object Failure）

在发生系统故障时，Ray 将尝试恢复任何丢失的对象，如果无法恢复，并且 worker 试图获取对象的值，则会引发应用程序级异常。

在更高层次上，Ray 保证如果所有者仍然活着，将尝试恢复对象。如果恢复失败，所有者将在异常中填写原因。如果对象的所有者已经死亡，任何试图获取该值的 worker 都会收到一个关于所有者死亡的异常，即使对象副本仍然存在于集群中。

#### 小对象

小对象存储在所有者的进程中对象存储中，因此如果所有者死亡，小对象将丢失。任何试图在未来获取对象值的 worker 都将收到所有者已死亡的异常，并将错误存储在本地进程内对象存储中。

#### 大对象和谱系重建

如果不存在其它副本，Ray 将尝试通过恢复对象。这是指通过重新执行创建对象的任务来恢复丢失的对象。如果任务的依赖关系也丢失，或者以前由于垃圾收集而被逐出，那么这些对象将被递归地重建。

谱系重建通过在每个对象旁边保持额外的“谱系引用计数”来工作。这是指依赖于对象本身可能被重新执行的任务数。如果任务或下游任务返回的任何对象仍在范围内，则可以重新执行任务。一旦谱系引用计数达到 0，Ray 将垃圾回收创建对象的 task specification。请注意，这是一个独立于对象值的垃圾收集机制：如果对象的直接引用计数达到 0，则即使其谱系计数保持在范围内，其值也将从 Ray 的对象存储中进行垃圾收集。

请注意，谱系重建可能会导致比通常更高的 Driver 内存使用率。如果总大小超过系统范围阈值（默认值为1GB），每个 Ray 工作程序将尝试回收其本地缓存的谱系计数。

谱系重建目前有以下限制。如果应用程序不满足这些要求，那么它将收到一个重建失败的异常：

- 对象及其任何传递依赖项必须由任务（actor or non-actor）生成。这意味着 ray.put 创建的对象不可恢复。请注意，由 “ray.put” 创建的对象始终与其所有者存储在同一节点上，所有者将最终与该节点共享；因此，在 “ray.put” 对象的主副本丢失的情况下，应用程序将收到一个通用的 “OwnerDiedError”。
- 任务被假定为确定性和幂等性的。因此，默认情况下，由 Actor 任务创建的对象是不可重构的。如果用户将参与者的 “max_task_retrys” 和 “max_restarts” 设置为非零值，则可以作为谱系的一部分重新执行参与者任务。
- 任务将仅重新执行其最大重试次数。默认情况下非 Actor 最多重试 3 次，Actor 不能重试。你可以通过 “max_retrys” 和 “max_task_retry” 参数修改。
- 对象的所有者必须仍然活着。

如果存储在分布式内存中的对象的所有者丢失：在对象解析期间，raylet 将尝试定位对象的副本。同时，raylet 将定期与所有者联系，以检查所有者是否还活着。如果所有者已死亡，raylet 将存储一个系统级错误，该错误将在对象解析期间抛出给引用持有者。

## 任务管理

### 任务执行

![img](./images/36_Ray2.0 - 18.png)

任务调用方在从分布式调度程序请求资源之前等待创建**所有任务参数可用**。在许多情况下，任务的调用者也是任务参数的所有者。任务的调用方可能借用了任务参数，即它**从所有者处收到了参数 “ObjectRef” 的反序列化副本**。在这种情况下，任务调用方必须通过与参数所有者执行协议来确定参数是否已创建。借用进程将在反序列化 “ObjectRef” 时与所有者联系。一旦创建了对象，所有者就会做出响应，借用者会将对象标记为就绪。如果所有者失败，借用者也会将该对象标记为已准备好，因为对象的命运与所有者共享。

任务可以有三种类型的参数：plain values, inlined objects, 和 non-inlined objects.

plain values 不需要依赖关系解析。

inlined objects 是足够小的对象，可以存储在进程内存储中（默认阈值为100KB）。调用者可以将这些直接复制到 task specification 中。

non-inlined objects 是存储在分布式对象存储中的对象。其中包括大对象和已被所有者以外的进程借用的对象。在这种情况下，调用者将要求 raylet 在调度决策期间说明这些依赖关系。raylet 将等待这些对象成为其节点的本地对象，然后再给予依赖这个任务的 worker 。这确保了正在执行的工作程序在接收任务时不会阻塞（等待对象变为本地对象）。

### 资源调度实现

任务调用程序通过首先向请求的首选 raylet 发送资源请求来调度任务。可选择以下任一项：

- 按数据位置：如果任务的对象参数存储在共享内存中，则调用方选择本地对象参数最多的节点。该信息通过调用方的本地对象目录检索，可能是过时的（例如，如果同时发生对象传输或逐出）。
- 按节点关联：如果目标 raylet 使用了 NodeAffinitySchedulengStrategy 指定。
- 默认情况下使用本地的 raylet。

![img](./images/36_Ray2.0 - 19.png)

首选 raylet 对请求进行排队，如果它要给予资源，则使用当前租给调用者的本地 worker 的地址来响应调用者。只要主动请求方和租用的 worker 还活着，租约就保持活动状态，并且 raylet 确保在租约处于活动状态时，其他客户端都不能使用该 worker。为了确保公平性，如果没有剩余的任务或已经过了足够的时间（例如，几百毫秒），调用方将返回空闲的工作程序。

请求方可以将任意数量的任务调度到租用的 worker 上，只要这些任务与授权的资源请求兼容即可。因此，租用可以被认为是一种以避免与调度器进行类似调度请求的通信优化方案。如果它具有以下相同的条件，调度请求可以重用租用的 worker：

- 资源规模，如 CPU：1。
- 共享内存任务参数，因为这些参数必须在任务执行之前在节点上设置为本地。注意，小任务参数不需要匹配，因为这些参数被内联到任务参数中。此外，在数据结构内部传递的 ObjectRef 不需要匹配，因为 Ray 不会在任务开始之前将这些 ObjectRef 设置为本地。
- 运行时环境，因为租用的工作程序在此环境中启动。

![img](./images/36_Ray2.0 - 20.png)

*调用方可以持有多个 worker 租约以提高并行性。worker 租约在多个任务之间缓存，可以以减少调度程序的负载。*

如果首选 raylet 选择不在本地给予资源，它还可以使用远程 raylet 的地址来响应调用者，调用者应该在该地址重试资源请求。这就是所谓的溢出调度。远程 raylet 可以根据其本地资源的当前可用性同意或拒绝资源请求。如果资源请求被拒绝，则调用者将再次从首选 raylet 请求，并且重复相同的过程，直到某个 raylet 授予资源请求。

![img](./images/36_Ray2.0 - 21.png)

*在溢出调度期间，本地 raylet 将调用者的请求重定向到可能有可用资源的远程 raylet。*

### 资源管理和调度

Ray 中的资源是一个键-值对，其中键表示资源名称，值是一个浮点数。为了方便起见，Ray 调度器具有对CPU、GPU 和内存资源类型默认支持。 Ray 的资源是逻辑上的资源，不需要与物理资源进行 1 对 1 映射，默认情况下，Ray将每个节点上的逻辑资源数量设置为 Ray 自动检测到的物理数量。

用户还可以使用自定义资源需求，例如，指定资源需求｛“custom_resource”：0.01｝。可以在启动时向节点添加自定义资源。

分布式调度程序会尝试匹配集群中合适的资源，如一个任务要求 ｛“CPU”：1.0，“GPU”：1.0，那么此任务只能在 CPU >=1 和 GPU >=1 的节点上调度。默认每个`@ray.remote` 函数一定会需要 1 个 CPU 来运行。对于 actor 来说，默认是 0 个 CPU。这样一来，单个节点可以承载比其核心更多的 actor，从而将 CPU 尽可能留给操作系统。

有一些资源需要特殊处理：

- CPU、GPU 和“内存”的数量在 Ray 启动期间自动检测。
- 将 GPU 资源分配给任务将自动设置到 worker 的 CUDA_VISIBLE_DEVICES 系统变量，通过 ID 的方式限制使用的 GPU。

注意，因为资源请求是逻辑上的，所以 Ray 不会强制执行物理资源限制。用户可以指定准确的资源需求，例如，为具有 n 个线程的任务指定 “num_cpus=n” 。



