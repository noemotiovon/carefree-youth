# Llama.cpp 接入 ACL Graph 性能优化介绍

## 背景

[Llama.cpp](https://github.com/ggerganov/llama.cpp) 是一个轻量级、纯 C/C++ 实现的大语言模型推理框架，能够在多种硬件平台上高效运行。为了进一步发挥华为昇腾 AI 处理器的潜能，我们尝试将 Llama.cpp 的算子执行逻辑与 **ACL Graph**（Ascend Computing Language 图模式）进行深度集成，从而实现更高效的推理性能。

在传统的 **Op-by-Op** 模式下，每个算子的执行都需要独立下发，涉及算子构建、内存拷贝和同步操作，这在大规模推理任务中会带来明显的开销。而 **ACL Graph 模式** 能够将一系列算子组合成计算图，并在图级别完成优化与调度，从而减少算子下发次数，提升算子融合与内存调度效率。

下图展示了 **ACL Graph 相较于传统 Op-by-Op 模式的优化示意**。可以看到，ACL Graph 主要解决的是 **CPU 端瓶颈（CPU Bound）**：通过减少算子下发，降低 CPU 压力，避免 NPU 长时间等待 CPU 调度。

- 对于参数规模较小的模型，这种优化效果尤为显著。例如在 Llama.cpp 上测试 **Qwen2.5-0.5B** 时，性能提升超过一倍。
- 对于参数规模较大的模型，性能瓶颈通常来自 NPU 端的算力本身（如下图中 A、B、C、D、E 等算子耗时较长），因此 ACL Graph 带来的收益相对有限。

![img](images/1_acl_graph.png)

## ACL Graph 接入

ACL Graph 模式的接入流程如图所示，主要分为 **图匹配**、**图捕获** 和 **图重放** 三个阶段。

![img](images/2_graph_process.png)

### 图匹配

在执行算子序列前，需要判断其是否与已有的计算图匹配：

1. 若匹配成功，直接进行图重放；
2. 若不匹配，则销毁旧图，重新捕获并生成新图，再进行重放。

图匹配的核心判断条件包括：

- 算子序列的算子数量是否与图中的一致；
- 各算子类型是否相同；
- 各算子的输入输出地址是否一致；
- 各算子的输入输出维度是否一致。

### 图捕获

图捕获的过程就是将当前执行的算子序列转化为计算图，具体步骤如下：

1. 调用 `aclmdlRICaptureBegin` 开始图捕获；
2. 按照 **Op-by-Op** 的方式依次执行算子序列；
3. 调用 `aclmdlRICaptureEnd` 结束捕获，得到完整计算图。

### 图重放

对于已捕获的计算图，可通过 `aclmdlRIExecuteAsync` 进行重放。
所谓重放，就是 **Launch ACL Graph + Execute Graph** 的过程，即直接调度整个计算图执行，而非逐算子下发。



## GGML_OP_CPY 算子问题

在将 ACL Graph 接入 Llama.cpp 时，最大的挑战来自运算符 **`GGML_OP_CPY`**。

Llama.cpp 的各个后端接入实际上是通过框架维护的一套 **API 和运算符抽象（GGML_OP）** 来完成的，每个后端需要实现对应的 API 和运算符逻辑。在进行 **图捕获** 判断时，需要校验以下信息是否一致：

- 节点的 **地址**
- 节点的 **维度**
- **节点个数**
- **运算符类型**

只有当这些信息完全一致时，才可以直接重放已捕获的图；否则就需要重新构图。

### 问题：GGML_OP_CPY 的地址变化

在 Llama.cpp 中，`GGML_OP_CPY` 主要用于 **生成并记录 KV Cache** 的过程。每次推理时，最新的 KV Cache 都会被拷贝到一个新的目标地址中。这导致 **每次算子节点的目的地址（dst）都会改变**，进而触发 **频繁的图重建**。结果是：

- 每个 token 都需要重新捕获和构建计算图；
- 图重放失去了意义；
- 性能甚至只有普通模式（Op-by-Op）的 **50% 左右**。

然而，本质上 `GGML_OP_CPY` 的变化只有 **目的地址不同**，其他信息均保持一致。因此，我们尝试了一些优化思路。

### 尝试的方案

1. **间接寻址方案（参考 CUDA Graph）**

   - 记录所有的 `dst` 地址，并维护一个二级指针；
   - 在调用底层 CANN 算子（如 InplaceCopy/Cast）时，将二级指针和索引传递给算子，由算子通过 **地址 + 索引** 获取实际 `dst` 地址；
   - 从而实现“固定的逻辑地址”，避免频繁构图。
   - **问题**：此方案需要额外开发算子，且 aclnn 对间接寻址支持存在不确定性，最终被否决。

2. **固定内存方案**

   - 申请一块固定内存，将所有 `dst` 都映射到这里，保证 ACL 调用时地址相同；
   - 但这会导致 **KV Cache 读取错误**：因为实际计算出的 KV Cache 被写入了固定内存，而没有放到真正的 KV Cache 区域。

3. **固定内存 + 间接拷贝**

   - 结合 `aclrtMemcpyAsyncWithDesc` 提供的间接寻址，将计算结果先写入固定内存，再以间接方式拷贝到 KV Cache 中实际位置；

   - **问题**：KV Cache 中 `k` 的存储地址是 **完全不连续的**，对于存储上不连续的张量，`aclrtMemcpy` 无法直接拷贝；逐个拷贝也不可行，因为 `aclrtMemcpy` 的源地址和目的地址都必须 **64 字节对齐**。

     - 一种情况是内存上连续，但因为转置等操作导致逻辑访问不连续；

     - 另一种情况则是物理存储本身不连续（如下图所示，每个 token 的 K Cache 被分散存放在不同位置），即刚才提到的 **完全不连续**。

       ```
       x x x x x s o o
       x x x x x s o o
       x x x x x s o o
       x x x x x s o o
       ```

### 最终方案：使用 SET_ROWS 替代

最终，我们采用 `SET_ROWS` 算子 来规避 `CPY` 算子的问题。

- `SET_ROWS` 可以直接设置 tensor 的某一行数据；
- KV Cache 在初始化时已经分配好内存，每个 token 的 cache 存储位置是固定的；
- 在更新 KV Cache 时，可以通过 `SET_ROWS` 将新生成的 KV Cache 数据写入对应行；
- 更重要的是，`SET_ROWS` 的输入地址始终固定（KV Cache 的起始地址），这样就避免了频繁重构图的问题。

通过这一改造，Llama.cpp 在接入 ACL Graph 时成功绕过了 `CPY` 带来的性能瓶颈，大幅提升了推理效率。

## 图匹配优化

在早期实现中，图匹配逻辑仅基于 **单一计算图**，这使得匹配命中率较低。为了提升匹配成功的概率，我们引入了 **LRU（Least Recently Used）Cache** 机制。

在进行图匹配时，系统会遍历 Cache 中所有已保存的计算图，逐一进行匹配：

- 如果找到匹配的计算图，则直接复用该图并进行重放，并基于 **LRU 策略** 更新 Cache；
- 如果没有任何图匹配成功，则重新执行图捕获，并基于 **LRU 策略** 更新 Cache，替换掉最久未被使用的计算图。

通过引入 LRU Cache，能够显著提升图复用率，减少频繁的图构建开销，从而进一步提高整体推理性能。

![img](images/3_lru_cache.png)

## 图捕获优化

在 **prefill 阶段**，算子的维度信息与 prompt 的长度高度相关，导致计算图形态随输入变化而频繁改变。即使成功捕获了图，由于其复用频率极低，每次仍需执行“先捕获、再执行”的流程，不仅无法发挥 Graph 重放的优势，还会增加 **LRU Cache** 的管理负担（频繁触发图的销毁与替换）。

为降低这部分开销，我们在 prefill 阶段保留 **Op-by-Op 模式**，避免不必要的图捕获与 Cache 更新。而在 **decode 阶段**，每次推理的 `seq_length` 固定为 1，算子序列和维度保持一致，计算图可以稳定复用，此时采用 **ACL Graph 模式** 能够带来显著收益。

![img](images/4_prefill_opti.png)



