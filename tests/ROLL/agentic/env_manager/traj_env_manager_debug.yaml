defaults:
  - ../../../examples/config/traj_envs.yaml@_here_
  - ../../../examples/config/traj_envs_gem_games.yaml@_here_
  - ../../../examples/config/traj_envs_gem_rg.yaml@_here_

rollout_batch_size: 32
sequence_length: 8192
pretrain: Qwen/Qwen2.5-0.5B-Instruct

train_env_manager:
  format_penalty: -0.15 # sokoban env penalty_for_step=-0.1
  max_env_num_per_worker: 1
  num_env_groups: 1
  # under the same group, the env config and env seed are ensured to be equal
  group_size: 1
  tags: [deep_math]
  num_groups_partition: [1] # If not set, all env names divide nums equally. Under the same group, the env config and env seed (prompt) are equal in each generation
  llm_proxy:
    proxy_type: random
#  llm_proxy:
#    proxy_type: openai
#    proxy_config:
#      base_url: https://offline-whale-wave.alibaba-inc.com/api/v2/services/aigc/text-generation/v1/chat/completions
#      api_key: xxx
#      model_name: Qwen2.5-72B-Instruct-Chatflow

custom_envs:
  SimpleSokoban:
    ${custom_env.SimpleSokoban}
  FrozenLake:
    ${custom_env.FrozenLake}
  NaturalQuestions:
    ${custom_env.NaturalQuestions}
  GemGame:
    ${gem_games.Hangman}
  CliEnv:
    ${custom_env.CliEnv}
  deep_math:
    ${custom_env.deep_math}
  CodeContest:
    ${custom_env.CodeContest}

actor_infer:
  generating_args:
    max_new_tokens: ${max_tokens_per_step} # single-turn response length
    top_p: 0.99
    top_k: 100
    num_beams: 1
    temperature: 0.99
    num_return_sequences: 1

max_tokens_per_step: 2048
max_actions_per_traj: 10

env_manager_cls: roll.pipeline.agentic.env_manager.traj_env_manager.TrajEnvManager
custom_env:
  CliEnv:
    env_type: cli
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: ${env_manager_cls}
    agent_system_template: ${cli_agent_system_template}
    agent_template: ${cli_agent_template}
    env_config:
      max_steps: ${max_actions_per_traj}
      workspace_dir: /tmp/cli_workspace
      sandbox_image: hub.docker.alibaba-inc.com/chatos/iflow-cli:3.0
      sandbox_base_url: https://xrl-sandbox.alibaba-inc.com
      auto_clear_seconds: 1200
      format_penalty: -0.1
  SimpleSokoban:
    env_type: sokoban
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: ${env_manager_cls}
    use_thread_lock: true
    agent_system_template: ${agent_system_template}
    agent_template: ${agent_template}
    env_config: # keys should be a subset of SokobanConfig
      action_pattern: ${all_response_pattern}
      dim_room: [10, 10]
      num_boxes: 1
  FrozenLake:
    env_type: frozen_lake
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: ${env_manager_cls}
    use_thread_lock: true
    agent_system_template: ${agent_system_template}
    agent_template: ${agent_template}
    env_config:
      action_pattern: ${all_response_pattern}
      max_steps: ${max_actions_per_traj}
      is_slippery: false
  NaturalQuestions:
    env_type: "qa:NaturalQuestions"
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: ${env_manager_cls}
    agent_system_template: ${single_prompt_agent_system_template}
    agent_template: ${single_prompt_agent_template}
    env_config:
      max_steps: 10
      dataset_name: /Users/pan/Downloads/huggingface/NaturalQuestions
    tool_wrapper:
      wrapper_args:
        tool_reward: 0.05
        tool_success_reward: 0.25
        max_tool_uses: 5
      tool_configs:
        - tool_id: search
          tool_args:
            search_url: http://localhost:8000/retrieve
            topk: 3
  deep_math:
    env_type: "roll_math"
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: ${env_manager_cls}
    agent_system_template: ${single_prompt_agent_system_template}
    agent_template: ${single_prompt_agent_template}
    env_config:
      dataset_name: data/math_deepmath_deal.jsonl
      split: train
      question_key: prompt
      answer_key: ground_truth
  CodeContest:
    env_type: "code:CodeContest"
    max_steps: ${max_actions_per_traj}
    max_tokens_per_step: ${max_tokens_per_step}
    env_manager_cls: ${env_manager_cls}
    agent_system_template: ${single_prompt_agent_system_template}
    agent_template: ${single_prompt_agent_template}
    env_config:
      max_steps: 10
      dataset_name: CodeContest
    tool_wrapper:
      wrapper_args:
        tool_reward: 0.05
        tool_success_reward: 0.25
        max_tool_uses: 5
      tool_configs:
        - tool_id: python_code
          tool_args:
            timeout: 5
            sandbox_type: none
            keep_error_last_line: false


cli_agent_system_template: You're a helpful assistant. You are a good game player. You are aiming to get high reward in the game.
cli_agent_template: |
  {observation}
  Strictly follow this format:
  1. output format is '<answer> [your answer] </answer>' with no extra text. 
  2. You have {actions_left} actions left. 
  3. Max response length: {max_response_length} words (tokens).
  Decide the next action:
